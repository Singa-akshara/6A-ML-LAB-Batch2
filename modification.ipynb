{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('file.csv')\n",
        "\n",
        "\n",
        "label_encoders = {}\n",
        "categorical_features = ['Gender', 'Education Level', 'Job Title']\n",
        "for col in categorical_features:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "df.dropna(inplace=True)\n",
        "#df.drop(['Age','Gender'])\n",
        "X = df[['Age','Gender','Education Level', 'Job Title', 'Years of Experience']]\n",
        "#X=df[['Years of Experience']]\n",
        "y = df['Salary']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "#print(f'R-squared (R2): {r2:.2f}')\n",
        "\n",
        "# You can also print the coefficients and intercept\n",
        "print('Intercept:', model.intercept_)\n",
        "print('Coefficients:', model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFSK9_824Dqm",
        "outputId": "c0d1d00a-2672-44da-f5aa-bb629a3d4ff2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 885414686.25\n",
            "Root Mean Squared Error (RMSE): 29755.92\n",
            "Intercept: 98085.48053289721\n",
            "Coefficients: [-1770.95891227  5544.55220841  2110.22173241   -28.09677576\n",
            "  8780.58074274]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('file.csv')\n",
        "\n",
        "\n",
        "label_encoders = {}\n",
        "categorical_features = ['Gender', 'Education Level', 'Job Title']\n",
        "for col in categorical_features:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "X = df[['Age', 'Gender', 'Education Level', 'Job Title', 'Years of Experience']]\n",
        "y = df['Salary']\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "#print(f'R-squared (R2): {r2:.2f}')\n",
        "\n",
        "# Note: Decision Tree models don't have coefficients and an intercept in the same way linear models do.\n",
        "# You can inspect the feature importances instead.\n",
        "#print('Feature Importances:', model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vnr4uk4dwn",
        "outputId": "d5a8fee1-68a0-4f68-d141-59f6c4389c1c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 107048440.95\n",
            "Root Mean Squared Error (RMSE): 10346.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import OneHotEncoder, PolynomialFeatures\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('file.csv')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Separate features and target\n",
        "X = df[['Age','Gender','Education Level', 'Job Title', 'Years of Experience']]\n",
        "y = df['Salary']\n",
        "\n",
        "# Define categorical and numerical features\n",
        "categorical_features = ['Gender', 'Education Level', 'Job Title']\n",
        "numerical_features = ['Age', 'Years of Experience']\n",
        "\n",
        "# Create a column transformer for preprocessing\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', PolynomialFeatures(degree=2, include_bias=False), numerical_features), # Add polynomial features\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)]) # One-Hot Encode\n",
        "\n",
        "# Create a pipeline that includes preprocessing and the model\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                      ('regressor', LinearRegression())])\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "print(f'R-squared (R2): {r2:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSMpYLoCC3IN",
        "outputId": "7fd23af7-ceb9-4b1b-cfb1-63d0045f5e68"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 243994925.85\n",
            "Root Mean Squared Error (RMSE): 15620.34\n",
            "R-squared (R2): 0.91\n"
          ]
        }
      ]
    }
  ]
}