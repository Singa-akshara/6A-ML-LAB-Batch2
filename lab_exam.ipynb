{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "# You can use various strategies like dropping rows with NaNs or imputing\n",
        "# For simplicity, let's drop rows with any NaN values\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('file.csv')\n",
        "\n",
        "# Handle categorical features\n",
        "# For 'Gender', 'Education Level', 'Job Title', we'll use Label Encoding\n",
        "label_encoders = {}\n",
        "categorical_features = ['Gender', 'Education Level', 'Job Title']\n",
        "for col in categorical_features:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define features (X) and target (y) again after handling NaNs\n",
        "X = df[['Age', 'Gender', 'Education Level', 'Job Title', 'Years of Experience']]\n",
        "y = df['Salary']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "#print(f'R-squared (R2): {r2:.2f}')\n",
        "\n",
        "# You can also print the coefficients and intercept\n",
        "print('Intercept:', model.intercept_)\n",
        "print('Coefficients:', model.coef_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFSK9_824Dqm",
        "outputId": "d432bbed-6dda-4d0f-82cb-c1d4ad8fa2b4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 885414686.25\n",
            "Root Mean Squared Error (RMSE): 29755.92\n",
            "Intercept: 98085.48053289721\n",
            "Coefficients: [-1770.95891227  5544.55220841  2110.22173241   -28.09677576\n",
            "  8780.58074274]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('file.csv')\n",
        "\n",
        "# Handle categorical features\n",
        "# For 'Gender', 'Education Level', 'Job Title', we'll use Label Encoding\n",
        "label_encoders = {}\n",
        "categorical_features = ['Gender', 'Education Level', 'Job Title']\n",
        "for col in categorical_features:\n",
        "    label_encoders[col] = LabelEncoder()\n",
        "    df[col] = label_encoders[col].fit_transform(df[col])\n",
        "\n",
        "# Handle missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[['Age', 'Gender', 'Education Level', 'Job Title', 'Years of Experience']]\n",
        "y = df['Salary']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize and train the Decision Tree Regressor model\n",
        "# You can adjust parameters like max_depth, min_samples_split, etc.\n",
        "model = DecisionTreeRegressor(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'Mean Squared Error (MSE): {mse:.2f}')\n",
        "print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')\n",
        "#print(f'R-squared (R2): {r2:.2f}')\n",
        "\n",
        "# Note: Decision Tree models don't have coefficients and an intercept in the same way linear models do.\n",
        "# You can inspect the feature importances instead.\n",
        "#print('Feature Importances:', model.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7vnr4uk4dwn",
        "outputId": "429f3d74-de17-4ea0-cb63-170042c2965f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 107048440.95\n",
            "Root Mean Squared Error (RMSE): 10346.42\n"
          ]
        }
      ]
    }
  ]
}